{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "We need to pull in a few packages first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, h5py, numpy as np, glob, tqdm, sys, multiprocessing as mp\n",
    "from uuid import uuid4 as uuidgen\n",
    "sys.path.append('/scratch') # Set up local python environment\n",
    "from Core import utils\n",
    "from SparseNOvA import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_truth(file, im_idx):\n",
    "    '''Returns list of index locations of trainingdata for a given slicemap'''\n",
    "    keys = ['run','subrun','cycle','evt','subevt']\n",
    "    tag = { key: file['rec.training.slicemaps'][key][im_idx,0] for key in keys }\n",
    "    mask = None\n",
    "    for key in keys:\n",
    "        m = (file['rec.training.trainingdata'][key][:,0] == tag[key])\n",
    "        mask = m if mask is None else mask & m\n",
    "    true_idx = mask.nonzero()[0]\n",
    "    if len(true_idx) > 1:\n",
    "        raise Exception(f'{len(true_idx)} truths found for slicemap {im_idx}.')\n",
    "    return true_idx\n",
    "\n",
    "def get_alias(flav):\n",
    "    '''Function that alias interaction enum to the following list'''\n",
    "    # [0 == nu_mu, 1 == nu_e, 2 == nu_tau, 3 == NC, 4 == others]\n",
    "    if 0 <= flav < 4:    return 0\n",
    "    elif 4 <= flav < 8:  return 1\n",
    "    elif 8 <= flav < 12: return 2\n",
    "    elif flav == 13:     return 3\n",
    "    else:                return 4\n",
    "\n",
    "def process_file(filename):\n",
    "    \n",
    "    file = h5py.File(filename, 'r')\n",
    "    mask = np.nonzero(file['rec.mc']['nnu'][:,0]==1)[0]\n",
    "\n",
    "    # Loop over each neutrino image to look for the associated truth\n",
    "    for i, nu in enumerate(mask):\n",
    "        true_idx = match_truth(file, nu)\n",
    "        if len(true_idx) == 0: continue\n",
    "        image = file['rec.training.slicemaps']['slicemap'][nu]\n",
    "        xview, yview = image.reshape(2, 448, 384)[:]\n",
    "        truth = get_alias(file['rec.training.trainingdata']['interaction'][true_idx,0][0])\n",
    "        xsparse = torch.tensor(xview).float().to_sparse()\n",
    "        ysparse = torch.tensor(yview).float().to_sparse()\n",
    "        data = { 'xfeats': xsparse._values().unsqueeze(dim=-1),\n",
    "                 'xcoords': xsparse._indices().T.int(),\n",
    "                 'yfeats': ysparse._values().unsqueeze(dim=-1),\n",
    "                 'ycoords': ysparse._indices().T.int(),\n",
    "                 'truth': torch.tensor(truth).long() }\n",
    "        torch.save(data, f'/data/mp5/processed/{uuidgen()}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Pull the interesting events out of the HDF5 files, preprocess them, and write them as individual PyTorch files instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonswap = sorted(glob.glob('/data/mp5/nonswap/*.h5'))\n",
    "fluxswap = sorted(glob.glob('/data/mp5/fluxswap/*.h5'))\n",
    "tauswap = sorted(glob.glob('/data/mp5/tauswap/*.h5'))\n",
    "files = nonswap + fluxswap + tauswap\n",
    "\n",
    "with mp.Pool(processes=50) as pool: pool.map(process_file, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Remove all images with no hits in either view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 11791/3105407 [00:20<12:03, 4273.01it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/mp5/processed/8af5a52a-125e-4a48-b3e7-45b5e79ce8e4.pt is bad, removing.\n",
      "/data/mp5/processed/b40c50a6-9f95-4df9-9f75-09c21d45e998.pt is bad, removing.\n",
      "/data/mp5/processed/d91bd237-7b61-47d1-bee9-2f0e8857af9c.pt is bad, removing.\n",
      "/data/mp5/processed/afead1d3-ec1f-4d4f-8412-976315bf3efa.pt is bad, removing.\n",
      "/data/mp5/processed/ec3f31ec-7270-4908-82c5-b87962c5c5f6.pt is bad, removing.\n",
      "/data/mp5/processed/3fb08f09-0885-4549-b9ae-c3c85b3e584c.pt is bad, removing.\n",
      "/data/mp5/processed/35b566d6-3c90-4b01-86a0-6a0bd5f00524.pt is bad, removing.\n",
      "/data/mp5/processed/dd0b6ddc-7d67-4f81-a374-8124e5ea2b20.pt is bad, removing.\n",
      "/data/mp5/processed/5ebc6c13-1a1b-4d27-a3be-0198f944fbd1.pt is bad, removing.\n",
      "/data/mp5/processed/727ab1d7-0043-43e6-af34-e48c65ffa05d.pt is bad, removing.\n",
      "/data/mp5/processed/9798f053-c403-4327-a082-44c6beca0bc3.pt is bad, removing.\n",
      "/data/mp5/processed/4cfae11a-06cf-4099-a81f-33e449825839.pt is bad, removing.\n",
      "/data/mp5/processed/d14fafba-357a-4961-941c-5f4f082e8a8a.pt is bad, removing.\n",
      "/data/mp5/processed/93c383c4-c038-4583-8e16-a8e008b84a4b.pt is bad, removing.\n",
      "/data/mp5/processed/5a4e0e1c-682e-4f92-a7b1-0e58b0807417.pt is bad, removing.\n",
      "/data/mp5/processed/b16bf22b-9147-443c-a59f-1e07fc3332c8.pt is bad, removing.\n",
      "/data/mp5/processed/b9a865d3-9fc4-4f0e-ad03-c34d02c680eb.pt is bad, removing.\n",
      "/data/mp5/processed/4dd8aa64-187e-4690-ac8e-981da75ecd50.pt is bad, removing.\n",
      "/data/mp5/processed/f7a1c9ce-36a3-49bf-a2ef-9b550475144b.pt is bad, removing.\n",
      "/data/mp5/processed/203a541d-1753-4e41-8d65-48e59ecb4af6.pt is bad, removing.\n",
      "/data/mp5/processed/ec54d2c5-0f63-42f1-bc18-89d0471d3aa1.pt is bad, removing.\n",
      "/data/mp5/processed/7939fc28-0d6a-4599-af7a-ced503666ede.pt is bad, removing.\n",
      "/data/mp5/processed/75324f5a-9f75-4b69-913d-a68677438c5c.pt is bad, removing.\n",
      "/data/mp5/processed/e950c852-f836-454b-8448-3c85f0b96fd0.pt is bad, removing.\n",
      "/data/mp5/processed/0652854b-5f4d-4660-b9b2-9822ed4d5e11.pt is bad, removing.\n",
      "/data/mp5/processed/4ac45bdf-f5bf-4cdf-983f-9ef1c7b6d4af.pt is bad, removing.\n",
      "/data/mp5/processed/55ec0d2c-ab80-4c37-8441-48514f5a0340.pt is bad, removing.\n",
      "/data/mp5/processed/e2e8d572-7c74-423d-aea0-47a51e196fa9.pt is bad, removing.\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('/data/mp5/processed/*.pt')\n",
    "for filename in files:\n",
    "    data = torch.load(filename)\n",
    "    if data['xcoords'].shape[0] == 0 or data['ycoords'].shape[0] == 0:\n",
    "        print(f'{filename} is bad, removing.')\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
